{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGHEU9KtNCf",
        "outputId": "5e1ca53e-28d2-4e7c-f035-153f3527e7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcolCxp2t29V",
        "outputId": "db65b096-e003-4bec-a507-b8ef6ee0a88f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"House Price Prediction Script\"\"\"\n",
        "\n",
        "# ğŸš€ Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ğŸš€ Step 1: Load the Dataset\n",
        "file_path = \"/content/drive/MyDrive/GithubProjects/AmesHousingDataset/AmesHousing.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# ğŸš€ Step 2: Data Preprocessing\n",
        "# Remove spaces in column names\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "# Fill missing values\n",
        "num_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "df[num_features] = df[num_features].fillna(df[num_features].median())\n",
        "df[cat_features] = df[cat_features].fillna(\"None\")\n",
        "\n",
        "# ğŸš€ Step 3: Feature Engineering\n",
        "df['TotalSF'] = df['1st_Flr_SF'] + df['2nd_Flr_SF'] + df['Total_Bsmt_SF']\n",
        "df['SalePrice'] = np.log1p(df['SalePrice'])  # Log transformation of target\n",
        "\n",
        "# ğŸš€ Step 4: Encode Categorical Variables\n",
        "df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)\n",
        "\n",
        "# ğŸš€ Step 5: Feature Selection (Remove Low-Correlation Features)\n",
        "corr = df_encoded.corr()['SalePrice'].sort_values(ascending=False)\n",
        "low_corr_features = corr[abs(corr) < 0.1].index.tolist()\n",
        "df_encoded = df_encoded.drop(columns=low_corr_features)\n",
        "\n",
        "# ğŸš€ Step 6: Train-Test Split\n",
        "X = df_encoded.drop(columns=['SalePrice'])\n",
        "y = df_encoded['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ğŸš€ Step 7: Hyperparameter Tuning\n",
        "def optimize_model(model, param_grid):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(f\"Best Parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Random Forest Optimization\n",
        "rf_params = {'n_estimators': [100, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5]}\n",
        "best_rf = optimize_model(RandomForestRegressor(random_state=42), rf_params)\n",
        "\n",
        "# XGBoost Optimization\n",
        "xgb_params = {'n_estimators': [100, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 6]}\n",
        "best_xgb = optimize_model(XGBRegressor(random_state=42), xgb_params)\n",
        "\n",
        "# ğŸš€ Step 8: Model Training and Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    print(f\"{model.__class__.__name__} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
        "    return mae, rmse\n",
        "\n",
        "print(\"\\nğŸ¯ Evaluating Models:\")\n",
        "mae_rf, rmse_rf = evaluate_model(best_rf, X_test, y_test)\n",
        "mae_xgb, rmse_xgb = evaluate_model(best_xgb, X_test, y_test)\n",
        "\n",
        "# ğŸš€ Step 9: Ensemble Learning\n",
        "y_pred_ensemble = (best_rf.predict(X_test) + best_xgb.predict(X_test)) / 2\n",
        "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
        "rmse_ensemble = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
        "\n",
        "print(f\"\\nğŸ”¥ Ensemble Model - MAE: {mae_ensemble:.4f}, RMSE: {rmse_ensemble:.4f}\")\n",
        "\n",
        "# ğŸš€ Step 10: Save the Best Model\n",
        "joblib.dump(best_xgb, \"optimized_house_price_model.pkl\")\n",
        "\n",
        "# ğŸš€ Step 11: Make Predictions on New Data\n",
        "new_house = X_test.iloc[0:1]\n",
        "predicted_price = np.expm1(best_xgb.predict(new_house)[0])\n",
        "print(f\"\\nğŸ¡ Predicted House Price: ${predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUVdb1CnuDOx",
        "outputId": "6a3e8432-f61f-4013-801c-99f08a1c313b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZsImgXquOc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}