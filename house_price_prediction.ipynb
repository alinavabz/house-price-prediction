{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGHEU9KtNCf",
        "outputId": "5e1ca53e-28d2-4e7c-f035-153f3527e7dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcolCxp2t29V",
        "outputId": "db65b096-e003-4bec-a507-b8ef6ee0a88f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"House Price Prediction Script\"\"\"\n",
        "\n",
        "# 🚀 Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# 🚀 Step 1: Load the Dataset\n",
        "file_path = \"/content/drive/MyDrive/GithubProjects/AmesHousingDataset/AmesHousing.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# 🚀 Step 2: Data Preprocessing\n",
        "# Remove spaces in column names\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "\n",
        "# Fill missing values\n",
        "num_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "df[num_features] = df[num_features].fillna(df[num_features].median())\n",
        "df[cat_features] = df[cat_features].fillna(\"None\")\n",
        "\n",
        "# 🚀 Step 3: Feature Engineering\n",
        "df['TotalSF'] = df['1st_Flr_SF'] + df['2nd_Flr_SF'] + df['Total_Bsmt_SF']\n",
        "df['SalePrice'] = np.log1p(df['SalePrice'])  # Log transformation of target\n",
        "\n",
        "# 🚀 Step 4: Encode Categorical Variables\n",
        "df_encoded = pd.get_dummies(df, columns=cat_features, drop_first=True)\n",
        "\n",
        "# 🚀 Step 5: Feature Selection (Remove Low-Correlation Features)\n",
        "corr = df_encoded.corr()['SalePrice'].sort_values(ascending=False)\n",
        "low_corr_features = corr[abs(corr) < 0.1].index.tolist()\n",
        "df_encoded = df_encoded.drop(columns=low_corr_features)\n",
        "\n",
        "# 🚀 Step 6: Train-Test Split\n",
        "X = df_encoded.drop(columns=['SalePrice'])\n",
        "y = df_encoded['SalePrice']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 🚀 Step 7: Hyperparameter Tuning\n",
        "def optimize_model(model, param_grid):\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_absolute_error', verbose=1, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    print(f\"Best Parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Random Forest Optimization\n",
        "rf_params = {'n_estimators': [100, 300], 'max_depth': [10, 20, None], 'min_samples_split': [2, 5]}\n",
        "best_rf = optimize_model(RandomForestRegressor(random_state=42), rf_params)\n",
        "\n",
        "# XGBoost Optimization\n",
        "xgb_params = {'n_estimators': [100, 300], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 6]}\n",
        "best_xgb = optimize_model(XGBRegressor(random_state=42), xgb_params)\n",
        "\n",
        "# 🚀 Step 8: Model Training and Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    print(f\"{model.__class__.__name__} - MAE: {mae:.4f}, RMSE: {rmse:.4f}\")\n",
        "    return mae, rmse\n",
        "\n",
        "print(\"\\n🎯 Evaluating Models:\")\n",
        "mae_rf, rmse_rf = evaluate_model(best_rf, X_test, y_test)\n",
        "mae_xgb, rmse_xgb = evaluate_model(best_xgb, X_test, y_test)\n",
        "\n",
        "# 🚀 Step 9: Ensemble Learning\n",
        "y_pred_ensemble = (best_rf.predict(X_test) + best_xgb.predict(X_test)) / 2\n",
        "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
        "rmse_ensemble = np.sqrt(mean_squared_error(y_test, y_pred_ensemble))\n",
        "\n",
        "print(f\"\\n🔥 Ensemble Model - MAE: {mae_ensemble:.4f}, RMSE: {rmse_ensemble:.4f}\")\n",
        "\n",
        "# 🚀 Step 10: Save the Best Model\n",
        "joblib.dump(best_xgb, \"optimized_house_price_model.pkl\")\n",
        "\n",
        "# 🚀 Step 11: Make Predictions on New Data\n",
        "new_house = X_test.iloc[0:1]\n",
        "predicted_price = np.expm1(best_xgb.predict(new_house)[0])\n",
        "print(f\"\\n🏡 Predicted House Price: ${predicted_price:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUVdb1CnuDOx",
        "outputId": "6a3e8432-f61f-4013-801c-99f08a1c313b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZsImgXquOc9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}